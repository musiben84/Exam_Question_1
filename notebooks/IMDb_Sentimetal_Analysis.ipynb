{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdee86f1",
   "metadata": {},
   "source": [
    "\n",
    "# Part A – NLP Preprocessing and Feature Engineering\n",
    "\n",
    "This notebook covers:\n",
    "- Loading the 50,000 IMDb reviews.\n",
    "- Inspecting raw text samples.\n",
    "- Cleaning and normalizing text.\n",
    "- Creating TF–IDF vectors for classical ML.\n",
    "- Creating tokenized, padded sequences for deep learning.\n",
    "- Reporting vocabulary size, average review length, and feature shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798763fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: C:\\Users\\Dell\\Desktop\\Group_2\\imdb_sentiment_project\\data\\aclImdb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports and Global Config\n",
    "\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For tokenization / padding (you can choose another library if you prefer)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_IMDB_DIR = DATA_DIR / \"aclImdb\"  # update this if you use a different path\n",
    "\n",
    "print(\"Data directory:\", RAW_IMDB_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6690db",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Load the IMDb Dataset\n",
    "\n",
    "The IMDb Large Movie Review Dataset has:\n",
    "- 25,000 labeled training reviews\n",
    "- 25,000 labeled test reviews\n",
    "Each review is either **positive (pos)** or **negative (neg)**.\n",
    "\n",
    "Implement a loader that walks the `train/pos`, `train/neg`, `test/pos`, `test/neg`\n",
    "directories, reads the text files, and stores them in a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de3b3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  split\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      1  train\n",
       "1  Homelessness (or Houselessness as George Carli...      1  train\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...      1  train\n",
       "3  This is easily the most underrated film inn th...      1  train\n",
       "4  This is not the typical Mel Brooks film. It wa...      1  train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_imdb_split(split_dir):\n",
    "    \"\"\"Load a single split (train or test) from aclImdb.\n",
    "\n",
    "    Returns a DataFrame with columns: ['review', 'label', 'split']\n",
    "    where label is 1 for positive, 0 for negative.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for label, label_int in [(\"pos\", 1), (\"neg\", 0)]:\n",
    "        path = split_dir / label\n",
    "        for fname in sorted(path.glob(\"*.txt\")):\n",
    "            text = fname.read_text(encoding=\"utf-8\")\n",
    "            rows.append({\n",
    "                \"review\": text,\n",
    "                \"label\": label_int,\n",
    "                \"split\": split_dir.name\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ✅ NOW ACTUALLY LOAD THE DATA\n",
    "train_df = load_imdb_split(RAW_IMDB_DIR / \"train\")\n",
    "test_df = load_imdb_split(RAW_IMDB_DIR / \"test\")\n",
    "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ecda5",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Display Raw Samples and Dataset Size\n",
    "\n",
    "- Print 10 raw example reviews.\n",
    "- Describe number of reviews, class balance, and basic statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bacf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 50000\n",
      "label\n",
      "1    25000\n",
      "0    25000\n",
      "Name: count, dtype: int64\n",
      "split\n",
      "train    25000\n",
      "test     25000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Sample 33553 ---\n",
      "Label: 1\n",
      "When I first saw the ad for this, I was like 'Oh here we go. He's done High School Musical, but he can't coast along on that so now he's making appearances on other Disney shows'. Personally, I love The Suite Life and I'm a big fan of Ashely Tisdale. But for some reason, I'm not too keen on Zac Efron, although all my friends think he's the best thing since Jesse McCartney. But he really annoys me. Anyway, I watched the show (taking a break from English coursework) and was pleasantly surprised. T ...\n",
      "\n",
      "--- Sample 9427 ---\n",
      "Label: 1\n",
      "\"A Girl's Folly\" is a sort of half-comedy, half-mockumentary look at the motion picture business of the mid-1910's. We get a glimpse of life at an early movie studio, where we experience assembly of a set, running through a scene, handling of adoring movie fanatics, even lunch at the commissary. We are also privy to little known cinematic facts - for example, did you know that \"Frequently, 'movie' actors do not know the plot of the picture in which they are working\"?<br /><br />The plot of this  ...\n",
      "\n",
      "--- Sample 199 ---\n",
      "Label: 1\n",
      "I started watching the show from the first season, and at the beginning I was pretty skeptical about it. Original movie was kind of childish, and I was just looking for some sci-fi show while waiting for the BSG new season.<br /><br />But after few episodes I became a fan. I've loved the characters - the not-so-stupid-as-you-think-he-is Jack O'Neill, the not-only-smart Samantha Carter, the glorious Teal'c, women and kids favorite, and brilliant Dr. Daniel Jackson.<br /><br />Of course, stories s ...\n",
      "\n",
      "--- Sample 12447 ---\n",
      "Label: 1\n",
      "This is a more interesting than usual porn movie, because it is a fantasy adventure.The production values are high and the acting is(believe it or not) pretty good,especially Jenna Jameson.It`s also in widescreen which helps,it gives a feeling of a real motion picture and NOT a porn movie.But,of course it is a porn and a really good one with nice costumes,fine atmosphere and scenery.And by the way,the sex IS hot.<br /><br />Watch out for this one... ...\n",
      "\n",
      "--- Sample 39489 ---\n",
      "Label: 0\n",
      "I suppose for 1961 this film was supposed to be \" cool \" , but looking back now ( 45 years ) it's charm was just as silly as it's entertainment value ! Granted , the special effects do well on T.V. with the Series that started in 1964 , but for the BIG screen ?? I once had a fish tank that was equally as exciting ! I must agree about the Octopus scene near the end where it attached itself to the Seaview. Obviously not well staged...or trained ! Overall , it's pretty bad acting with shoddy specia ...\n",
      "\n",
      "--- Sample 42724 ---\n",
      "Label: 0\n",
      "This is a poor film. It certainly belongs in the how not to make a feature film category. Story, direction, acting and style are all flat as a pancake. Story consists of five  yes five  football matches spread out over the film's duration, each one more boringly filmed than the last, as a dysfunctional amateur football team go from strength to strength. That's it, that's the plot. It's hard to know who this film is aimed at. It's too banal for football fans and there's nothing in it for teens  ...\n",
      "\n",
      "--- Sample 10822 ---\n",
      "Label: 1\n",
      "I saw this movie when it was new. Later I rented it in Japan after having been here three years, afraid that I would cringe when I viewed it in the harsh light of my expanded international experience. The movie pleasantly surprised me with how accurately it portrays the culture clash between Japan and Pennsylvania (where I'm from). Not all the stuff is factually spot on, but the tone is perfect.<br /><br />I'm still in Japan many years later, and I continue to enjoy this film for its even-handed ...\n",
      "\n",
      "--- Sample 49498 ---\n",
      "Label: 0\n",
      "This meandering tale of mob revenge is simply not very interesting, even with Ed McMahon in a ripe role as the chief heavy. Jim Brown kicks ass effectively, Gloria Hendry proves again that she can bring life to even the poorest roles, and Brock Peters is decent as The Cop Who Plays By the Book. It's still dull and badly constructed, and even the print shown on cable is now emasculated of its original James Brown score. ...\n",
      "\n",
      "--- Sample 4144 ---\n",
      "Label: 1\n",
      "First, what I didn't like. The acting was not really up to the Hamlet standard. Branagh was really over-the-top, doing a lot of yelling mostly. In my opinion, those actors who were not big-name celebrities generally did a better job; though I would except Billy Crystal and Robin Williams. (And Charlton Heston, too, but I wasn't sure if he was playing at being a hack.) A lot of the ambiguities in the play were clearly resolved one way in the flashbacks.<br /><br />What I think speaks very much in ...\n",
      "\n",
      "--- Sample 36958 ---\n",
      "Label: 1\n",
      "As spectacle, it's hard to fault Nihon chinbotsu. The Japanese people have benefited from their intimate relationship with the sea, and the concept of the film implies that an entire world and way of life at risk - thanks to its volcanic heritage. From the standpoint of reality it's rather silly to have a drama wherein the entirety of Japan vanishes under the waves; why just Japan? <br /><br />So, presume instead that we have movie reality, fueled by spectacle (and popcorn), and some may find th ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: After loading `full_df`, run the following:\n",
    "\n",
    "if not full_df.empty:\n",
    "    print(\"Total reviews:\", len(full_df))\n",
    "    print(full_df['label'].value_counts())\n",
    "    print(full_df['split'].value_counts())\n",
    "\n",
    "    # Show 10 raw samples\n",
    "    sample_df = full_df.sample(10, random_state=42)\n",
    "    for i, row in sample_df.iterrows():\n",
    "        print(\"\\n--- Sample\", i, \"---\")\n",
    "        print(\"Label:\", row[\"label\"])\n",
    "        print(row[\"review\"][:500], \"...\")  # print first 500 chars\n",
    "else:\n",
    "    print(\"full_df is empty. Load the dataset first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2b4d3",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Text Cleaning\n",
    "\n",
    "Apply standard preprocessing steps:\n",
    "- Lowercasing\n",
    "- Remove HTML tags\n",
    "- Remove digits\n",
    "- Remove punctuation\n",
    "- Optional: remove stopwords, apply lemmatization\n",
    "\n",
    "Define a clean_text function and apply it to the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a592e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  Bromwell High is a cartoon comedy. It ran at t...   \n",
      "1  Homelessness (or Houselessness as George Carli...   \n",
      "2  Brilliant over-acting by Lesley Ann Warren. Be...   \n",
      "3  This is easily the most underrated film inn th...   \n",
      "4  This is not the typical Mel Brooks film. It wa...   \n",
      "\n",
      "                                        clean_review  \n",
      "0  bromwell high is a cartoon comedy it ran at th...  \n",
      "1  homelessness or houselessness as george carlin...  \n",
      "2  brilliant overacting by lesley ann warren best...  \n",
      "3  this is easily the most underrated film inn th...  \n",
      "4  this is not the typical mel brooks film it was...  \n"
     ]
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "def clean_text(text):\n",
    "    # Unescape HTML entities\n",
    "    text = html.unescape(text)\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags (simple regex)\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    # Remove digits\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "print(full_df[[\"review\", \"clean_review\"]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b53d92",
   "metadata": {},
   "source": [
    "\n",
    "## 4. TF–IDF Vectors and Token Sequences\n",
    "\n",
    "We need two representations of the text:\n",
    "- **TF–IDF** for classical ML (Logistic Regression / SVM / Naive Bayes)\n",
    "- **Tokenized, padded sequences** for deep learning (LSTM / GRU / CNN / etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8590dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (50000, 20000)\n",
      "Sequence shape: (50000, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters (you can tune)\n",
    "MAX_TFIDF_FEATURES = 20000\n",
    "MAX_NUM_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "\n",
    "if not full_df.empty:\n",
    "    texts = full_df[\"clean_review\"].tolist()\n",
    "    labels = full_df[\"label\"].values\n",
    "\n",
    "    # TF–IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=MAX_TFIDF_FEATURES)\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "    # Tokenizer + sequences\n",
    "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    X_seq = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    print(\"TF-IDF shape:\", X_tfidf.shape)\n",
    "    print(\"Sequence shape:\", X_seq.shape)\n",
    "else:\n",
    "    X_tfidf = None\n",
    "    X_seq = None\n",
    "    labels = None\n",
    "    tokenizer = None\n",
    "    tfidf_vectorizer = None\n",
    "    print(\"Load the dataset first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060c39b",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Statistics\n",
    "\n",
    "Report:\n",
    "- Vocabulary size\n",
    "- Average review length (in tokens) before padding\n",
    "- TF–IDF matrix shape\n",
    "- Sequence matrix shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47eca667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (tokenizer.word_index): 163229\n",
      "Average review length (tokens): 226.93236\n",
      "TF-IDF matrix shape: (50000, 20000)\n",
      "Sequence matrix shape: (50000, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not full_df.empty and tokenizer is not None:\n",
    "    # Vocabulary size\n",
    "    vocab_size = len(tokenizer.word_index)\n",
    "    print(\"Vocabulary size (tokenizer.word_index):\", vocab_size)\n",
    "\n",
    "    # Average review length (before padding)\n",
    "    raw_lengths = [len(seq) for seq in tokenizer.texts_to_sequences(full_df[\"clean_review\"].tolist())]\n",
    "    print(\"Average review length (tokens):\", np.mean(raw_lengths))\n",
    "\n",
    "    print(\"TF-IDF matrix shape:\", X_tfidf.shape if X_tfidf is not None else None)\n",
    "    print(\"Sequence matrix shape:\", X_seq.shape if X_seq is not None else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627bcbb",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Save Processed Artifacts\n",
    "\n",
    "Save TF–IDF features, sequences, labels, and vectorizers/tokenizers to disk,\n",
    "so the other notebooks (ML, DL, RL) can load them directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0972aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed features and objects to: ..\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not full_df.empty and X_tfidf is not None and X_seq is not None:\n",
    "    # Save numpy arrays\n",
    "    np.save(PROCESSED_DIR / \"X_seq.npy\", X_seq)\n",
    "    np.save(PROCESSED_DIR / \"labels.npy\", labels)\n",
    "\n",
    "    # Save TF-IDF matrix as sparse\n",
    "    from scipy import sparse\n",
    "    sparse.save_npz(PROCESSED_DIR / \"X_tfidf.npz\", X_tfidf)\n",
    "\n",
    "    # Save tokenizer and vectorizer using joblib\n",
    "    import joblib\n",
    "    joblib.dump(tokenizer, PROCESSED_DIR / \"tokenizer.joblib\")\n",
    "    joblib.dump(tfidf_vectorizer, PROCESSED_DIR / \"tfidf_vectorizer.joblib\")\n",
    "\n",
    "    # Save the cleaned dataframe (optional)\n",
    "    full_df.to_csv(PROCESSED_DIR / \"full_df_clean.csv\", index=False)\n",
    "\n",
    "    print(\"Saved processed features and objects to:\", PROCESSED_DIR)\n",
    "else:\n",
    "    print(\"Nothing to save yet. Make sure data is loaded and processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
